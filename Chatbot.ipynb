{"cells":[{"cell_type":"code","execution_count":14,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"_3NRRbFSO6e_"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-05-07 12:46:19.429594: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n","\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n","2023-05-07 12:46:19.431106: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n","\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n","2023-05-07 12:46:19.432107: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n","\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 312ms/step\n"]},{"name":"stderr","output_type":"stream","text":["2023-05-07 12:46:25.802891: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n","\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n","2023-05-07 12:46:25.804451: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n","\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n","2023-05-07 12:46:25.805614: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n","\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"]},{"name":"stdout","output_type":"stream","text":["Bot: Hello, Hello, how are you?\n","1/1 [==============================] - 0s 16ms/step\n"]}],"source":["import tensorflow as tf\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","import json\n","import string\n","import random\n","\n","# load the tokenizer and label encoder\n","with open('Saved Files/tokenizer.json') as f:\n","    data = json.load(f)\n","    tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(data)\n","\n","with open('Saved Files/label_encoder.json') as f:\n","    data = json.load(f)\n","    le = LabelEncoder()\n","    le.classes_ = np.array(data)\n","\n","with open('Saved Files/responses.json') as file:\n","    responses = json.load(file)\n","\n","# load the trained model\n","model = tf.keras.models.load_model('Saved Files/my_model.h5')\n","\n","# start the chatbot\n","while True:\n","    # get user input\n","    texts_p = []\n","    prediction_input = input('You: ')\n","    \n","    # preprocess the input\n","    prediction_input = prediction_input.lower() # convert to lowercase\n","    prediction_input = ''.join(c for c in prediction_input if c not in string.punctuation) # remove punctuation\n","    prediction_input = ' '.join(prediction_input.split())\n","                  \n","    #replacing words using dictionary\n","    with open(\"Datasets/dict.txt\", \"r\") as f:\n","        replacement_dict = eval(f.read())\n","    with open(\"Datasets/Other_words.txt\", \"r\") as f:\n","        special_words = [word.strip() for word in f.readlines()]\n","    if prediction_input in special_words:\n","        pass\n","    else:\n","        prediction_words = prediction_input.split()\n","        prediction_words = [replacement_dict[word] if word in replacement_dict else word for word in prediction_words]\n","        prediction_input = ' '.join(prediction_words)\n","                  \n","    \n","    texts_p.append(prediction_input)\n","    prediction_input = tokenizer.texts_to_sequences(texts_p)\n","    prediction_input = np.array(prediction_input).reshape(-1)\n","    prediction_input = pad_sequences([prediction_input],maxlen=18) # keep maxlen equal to at what the model was trained at. in model it is as 'input_shape'.\n","\n","    # get the output from the model\n","    output = model.predict(prediction_input)\n","    output = output.argmax()\n","    \n","    # find the tag and select a response\n","    response_tag = le.inverse_transform([output])[0]\n","    response = random.choice(responses[response_tag])\n","    \n","    # print the response\n","    print('Bot:', response)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOZFbNFky/RQblRu82tBHqO","mount_file_id":"1wVOfBUxIlQyAnmvueWcWH2cnAjiG9uM4","name":"","version":""},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":0}
